use std::path::PathBuf;
use std::sync::Arc;
use crate::config::Config;
use crate::business_layer::monitoring::{MetricsCollector, LatencyMonitor};
use crate::business_layer::streaming::ll_hls::{
    playlist_generator::LLHLSPlaylistGenerator,
    segment_manager::LLHLSSegmentManager,
    server_push::LLHLSServerPush,
    preload_hint::LLHLSPreloadHintManager,
};
use crate::data_layer::storage::s3_storage::S3Storage;
use super::ffmpeg_pipeline::FfmpegPipelineManager;

/// HLS ë³€í™˜ ê´€ë¦¬ì
pub struct HlsConversionManager {
    ffmpeg_manager: Arc<FfmpegPipelineManager>,
    playlist_generator: Arc<LLHLSPlaylistGenerator>,
    segment_manager: Arc<LLHLSSegmentManager>,
    server_push: Arc<LLHLSServerPush>,
    preload_hint_manager: Arc<LLHLSPreloadHintManager>,
    metrics_collector: Arc<MetricsCollector>,
    latency_monitor: Arc<LatencyMonitor>,
    s3_storage: Option<Arc<S3Storage>>,
    output_dir: String,
}

impl HlsConversionManager {
    /// ìƒˆë¡œìš´ HLS ë³€í™˜ ê´€ë¦¬ì ìƒì„±
    pub async fn new(
        config: Config,
        metrics_collector: Arc<MetricsCollector>,
        latency_monitor: Arc<LatencyMonitor>,
    ) -> Result<Self, Box<dyn std::error::Error + Send + Sync>> {
        let output_dir = config.hls.save_dir.clone();
        
        // FFmpeg íŒŒì´í”„ë¼ì¸ ê´€ë¦¬ì ìƒì„±
        let ffmpeg_manager = Arc::new(FfmpegPipelineManager::new(config.clone()));

        // LL-HLS ì»´í¬ë„ŒíŠ¸ë“¤ ìƒì„±
        let playlist_generator = Arc::new(LLHLSPlaylistGenerator::new(config.hls.clone()));
        let segment_manager = Arc::new(LLHLSSegmentManager::new(output_dir.clone(), config.hls.clone()));
        let server_push = Arc::new(LLHLSServerPush::new());
        let preload_hint_manager = Arc::new(LLHLSPreloadHintManager::new());

        // S3 ìŠ¤í† ë¦¬ì§€ ì´ˆê¸°í™”
        let s3_storage = match S3Storage::new(&config.s3).await {
            Ok(storage) => {
                println!("âœ… S3 Storage initialized: {}/{}", config.s3.region, config.s3.bucket);
                Some(Arc::new(storage))
            }
            Err(e) => {
                eprintln!("âš ï¸ Failed to initialize S3 storage: {}", e);
                None
            }
        };

        Ok(Self {
            ffmpeg_manager,
            playlist_generator,
            segment_manager,
            server_push,
            preload_hint_manager,
            metrics_collector,
            latency_monitor,
            s3_storage,
            output_dir,
        })
    }

    /// HLS ë³€í™˜ ì‹œì‘
    pub async fn start_hls_conversion(
        &self,
        stream_id: u32,
        stream_name: &str,
    ) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        // FFmpeg íŒŒì´í”„ë¼ì¸ ì‹œì‘
        self.ffmpeg_manager.start_pipeline(stream_id, stream_name).await?;

        // ì‹¤ì‹œê°„ S3 ì—…ë¡œë“œ ì‹œì‘
        if let Some(s3_storage) = &self.s3_storage {
            if let Err(e) = self.start_realtime_s3_upload(stream_name, s3_storage).await {
                eprintln!("âš ï¸ Failed to start realtime S3 upload: {}", e);
            }
        }

        // ë©”íŠ¸ë¦­ ê¸°ë¡ (ê¸°ì¡´ ë©”ì„œë“œê°€ ì—†ìœ¼ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬)
        // self.metrics_collector.record_stream_start(stream_name).await?;

        Ok(())
    }

    /// HLS ë³€í™˜ ì¤‘ì§€
    pub async fn stop_hls_conversion(
        &self,
        stream_id: u32,
        stream_name: &str,
    ) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        // FFmpeg íŒŒì´í”„ë¼ì¸ ì¤‘ì§€
        self.ffmpeg_manager.stop_pipeline(stream_id)?;

        // ë©”íŠ¸ë¦­ ê¸°ë¡ (ê¸°ì¡´ ë©”ì„œë“œê°€ ì—†ìœ¼ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬)
        // self.metrics_collector.record_stream_end(stream_name).await?;

        println!("ğŸ›‘ HLS conversion stopped for stream {} (key: {})", stream_id, stream_name);
        Ok(())
    }

    /// ìŠ¤íŠ¸ë¦¼ ë°ì´í„° ì²˜ë¦¬
    pub async fn process_stream_data(
        &self,
        stream_id: u32,
        data: &[u8],
    ) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        // FFmpeg íŒŒì´í”„ë¼ì¸ì— ë°ì´í„° ì „ì†¡
        self.ffmpeg_manager.send_data(stream_id, data)?;

        // ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        // self.metrics_collector.record_data_processed(stream_id, data.len()).await?;

        Ok(())
    }

    /// ì‹¤ì‹œê°„ S3 ì—…ë¡œë“œ ì‹œì‘
    async fn start_realtime_s3_upload(
        &self,
        stream_name: &str,
        s3_storage: &Arc<S3Storage>,
    ) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        let output_dir = PathBuf::from(&self.output_dir).join(stream_name);
        let stream_name_clone = stream_name.to_string();
        let s3_prefix = format!("hls_output/{}", stream_name);
        let s3_storage_clone = s3_storage.clone();

        tokio::spawn(async move {
            // S3 íŒŒì¼ ê°ì‹œê¸° ìƒì„±
            if let Some(upload_sender) = &s3_storage_clone.upload_sender {
                use crate::data_layer::storage::s3_file_watcher::S3FileWatcher;
                
                let watcher = S3FileWatcher::new(
                    upload_sender.clone(),
                    stream_name_clone.clone(),
                    s3_prefix,
                );

                if let Err(e) = watcher.start_watching(&output_dir).await {
                    eprintln!("âŒ Failed to start file watching: {}", e);
                }
            }
        });

        println!("ğŸ“¤ Realtime S3 upload started for stream '{}'", stream_name);
        Ok(())
    }

    /// S3 ì—…ë¡œë“œ ìƒíƒœ ì¡°íšŒ
    pub async fn get_s3_upload_status(&self, stream_name: &str) -> Option<crate::data_layer::storage::s3_types::UploadStatus> {
        if let Some(s3_storage) = &self.s3_storage {
            s3_storage.get_upload_status(stream_name).await
        } else {
            None
        }
    }

    /// ìŠ¤íŠ¸ë¦¼ì„ S3ì— ì—…ë¡œë“œ
    pub async fn upload_stream_to_s3(&self, stream_name: &str) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        if let Some(s3_storage) = &self.s3_storage {
            let local_dir = std::path::Path::new(&self.output_dir).join(stream_name);
            let s3_prefix = format!("hls_output/{}", stream_name);
            
            println!("ğŸ“¤ Starting S3 upload for stream '{}'...", stream_name);
            s3_storage.upload_directory_streaming(&local_dir, &s3_prefix, stream_name).await?;
            
            Ok(())
        } else {
            Err("S3 storage not initialized".into())
        }
    }

    /// S3ì—ì„œ ìŠ¤íŠ¸ë¦¼ ì‚­ì œ
    pub async fn delete_stream_from_s3(&self, stream_name: &str) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        if let Some(s3_storage) = &self.s3_storage {
            let s3_prefix = format!("hls_output/{}", stream_name);
            
            println!("ğŸ—‘ï¸ Deleting stream '{}' from S3...", stream_name);
            s3_storage.delete_directory(&s3_prefix).await?;
            
            Ok(())
        } else {
            Err("S3 storage not initialized".into())
        }
    }

    /// í™œì„± ìŠ¤íŠ¸ë¦¼ ìˆ˜ ì¡°íšŒ
    pub fn get_active_stream_count(&self) -> usize {
        self.ffmpeg_manager.active_pipeline_count()
    }

    /// ìŠ¤íŠ¸ë¦¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    pub fn has_stream(&self, stream_id: u32) -> bool {
        self.ffmpeg_manager.has_pipeline(stream_id)
    }
}
